---
title: "UK Analysis"
author: "Schaffer"
date: "March 27, 2017"
output: html_document
---
## UK Word Cloud

Abstract that i will eventually write.

```{r UKwordcloud, results='hide', echo=FALSE, message=FALSE}
# LIBRARIES
 library(twitteR)
 library(tm)
 library(wordcloud)
 library(RColorBrewer)
 library(plyr)
 library(dply)
 library(stringr)
 library(ggplot2)
 require(RCurl)
 library(ggmap)

# CONNECT TO TWITTER API
source("my_access.R") 
 
# NEXT LINE ESTABLISHES SAMPLE CITIES AND SAMPLE SIZE PER CITY 
N=2000  # tweets to request from each query
S=200  # radius in miles
lats=c(38.9,40.7,37.8,39,37.4,28,30,42.4,48,36,32.3,33.5,34.7,33.8,37.2,41.2,46.8,
       46.6,37.2,43,42.7,40.8,36.2,38.6,35.8,40.3,43.6,40.8,44.9,44.9)

lons=c(-77,-74,-122,-105.5,-122,-82.5,-98,-71,-122,-115,-86.3,-112,-92.3,-84.4,-93.3,
       -104.8,-100.8,-112, -93.3,-89,-84.5,-111.8,-86.8,-92.2,-78.6,-76.8,-116.2,-98.7,-123,-93)

#cities=DC, New York, San Fransisco, Colorado, Mountainview, Tampa, Austin, Boston, Seatle, Vegas, Montgomery, Phoenix, Little Rock, Atlanta, Springfield, Cheyenne, Bisruk, Helena, Springfield, Madison, Lansing, Salt Lake City, Nashville, Jefferson City, Raleigh, Harrisburg, Boise, Lincoln, Salem, St. Paul

donald=do.call(rbind,lapply(1:length(lats), function(i) searchTwitter('Donald+Trump',
              lang="en",n=N,resultType="recent",
              geocode=paste(lats[i],lons[i],paste0(S,"mi"),sep=","))))

# NEXT LINE IS LONS/LATS, FAVORITES, AND RETWEETS PER TWEET
donaldlat=sapply(donald, function(x) as.numeric(x$getLatitude()))
donaldlat=sapply(donaldlat, function(z) ifelse(length(z)==0,NA,z))  

donaldlon=sapply(donald, function(x) as.numeric(x$getLongitude()))
donaldlon=sapply(donaldlon, function(z) ifelse(length(z)==0,NA,z))  

donalddate=lapply(donald, function(x) x$getCreated())
donalddate=sapply(donalddate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))

donaldtext=sapply(donald, function(x) x$getText())
donaldtext=unlist(donaldtext)

isretweet=sapply(donald, function(x) x$getIsRetweet())
retweeted=sapply(donald, function(x) x$getRetweeted())
retweetcount=sapply(donald, function(x) x$getRetweetCount())

favoritecount=sapply(donald, function(x) x$getFavoriteCount())
favorited=sapply(donald, function(x) x$getFavorited())

data=as.data.frame(cbind(tweet=donaldtext,date=donalddate,lat=donaldlat,lon=donaldlon,
                           isretweet=isretweet,retweeted=retweeted, retweetcount=retweetcount,favoritecount=favoritecount,favorited=favorited))

# NEXT LINES CREATES WORD CLOUD OF JUST USA
# NEXT LINE CREATES CORPUS
corpus=Corpus(VectorSource(data$tweet))

# NEXT LINE CONVERTS TO LOWER CASE
corpus=tm_map(corpus,tolower)

# NEXT LINE REMOVES STOPWORDS
corpus=tm_map(corpus,function(x) removeWords(x,stopwords("english")))

# NEXT LINE CONVERTS TO PLAIN TEXT DOCUMENT 
corpus=tm_map(corpus,PlainTextDocument)

# NEXT LINE CREATES WORD CLOUD
col=brewer.pal(6,"Dark2")
wordcloud(corpus, min.freq=25, scale=c(5,2),rot.per = 0.25,
          random.color=T, max.word=45, random.order=F,colors=col)
```

##USA Sentiment Analysis

```{r USAsentiment, results='hide', echo=FALSE, message=FALSE}
# NEXT LINE GETS TWEETS WITH JUST GEOTAG
data=filter(data, !is.na(lat),!is.na(lon))
lonlat=select(data,lon,lat)

# NEXT LINE PUTS IT INTO GGMAPS FORMAT
result <- do.call(rbind, lapply(1:nrow(lonlat),
                     function(i) revgeocode(as.numeric(lonlat[i,1:2]))))
data2=lapply(result,  function(x) unlist(strsplit(x,",")))
address=sapply(data2,function(x) paste(x[1:3],collapse=''))
city=sapply(data2,function(x) x[2])
stzip=sapply(data2,function(x) x[3])
zipcode = as.numeric(str_extract(stzip,"[0-9]{5}"))   
state=str_extract(stzip,"[:alpha:]{2}")
data2=as.data.frame(list(address=address,city=city,zipcode=zipcode,state=state))

# NEXT CLEANS UP THE DATA
data=cind(data,data2)
tweet=data$tweet
tweet_list=lapply(tweet, function(x) iconv(x, "latin1", "ASCII", sub=""))
tweet_list=lapply(tweet, function(x) gsub("htt.*",' ',x))
tweet=unlist(tweet)
data$tweet=tweet

# NEXT SENTIMENT ANALYSIS
positives= readLines("positivewords.txt")
negatives = readLines("negativewords.txt")
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
  scores = laply(tweets,
                 function(tweet, positive_words, negative_words){
                 tweet = gsub("[[:punct:]]", "", tweet)
                 tweet = gsub("[[:cntrl:]]", "", tweet)   
                 tweet = gsub('\d+', '', tweet)         
                 tryTolower = function(x){
                     y = NA
                     try_error = tryCatch(tolower(x), error=function(e) e)
                     if (!inherits(try_error, "error"))
                       y = tolower(x)
                     return(y)
                   }
                   tweet = sapply(tweet, tryTolower)
                   word_list = str_split(tweet, "\s+")
                   words = unlist(word_list)
                   positive.matches = match(words, positive_words)
                   negative.matches = match(words, negative_words)
                   positive_matches = !is.na(positive_matches)
                   negative_matches = !is.na(negative_matches)
                   score = sum(positive_matches) - sum(negative_matches)
                   return(score)
                 }, positive_matches, negative_matches, .progress=.progress )
  return(scores)
}

score = sentiment_scores(tweet, positives, negatives, .progress='text')
data$score=score
```

